{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d9bd0d",
   "metadata": {},
   "source": [
    "No olvidar eliminar nbqa y pydocstyle y git\n",
    "\n",
    "ver lo de las comillas en out_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2960355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbqa pydocstyle --select=D107,D400,D401,D413 parse_metadata.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f67955",
   "metadata": {},
   "source": [
    "# parse_metadata\n",
    "\n",
    "input (2):  Suplementary_Table_1.csv y archivos\n",
    "\n",
    "output (2): samples.tsv, labels.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a5384b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def normalize_species(specie):\n",
    "    \"\"\"Normaliza el nombre de especies biológicas estandarizando prefijos y caracteres.\n",
    "\n",
    "    Args:\n",
    "        specie (str): Nombre de la especie a normalizar (ej: \"bifidobacterium_longum\").\n",
    "\n",
    "    Returns:\n",
    "        str: Nombre normalizado con prefijo 's__', espacios en lugar de guiones/barras bajas,\n",
    "             y capitalización (ej: \"s__Bifidobacterium longum\").\n",
    "\n",
    "    Examples:\n",
    "        >>> normalize_species(\"bifidobacterium_longum\")\n",
    "        's__Bifidobacterium longum'\n",
    "        >>> normalize_species(\"s__bifidobacterium-longum\")\n",
    "        's__Bifidobacterium longum'\n",
    "    \"\"\"\n",
    "    if not specie.startswith('s__'):\n",
    "        specie = 's__' + specie.replace('_', ' ').replace('-', ' ').capitalize()\n",
    "    else:\n",
    "        specie = 's__' + specie[3:].replace('_', ' ').replace('-', ' ').capitalize()\n",
    "    return specie\n",
    "\n",
    "def read_fasta(x, Dictionary=False):\n",
    "    \"\"\"\n",
    "    Lee un archivo FASTA y retorna su contenido junto con la información de las secuencias.\n",
    "\n",
    "    Args:\n",
    "        x (str): Ruta al archivo FASTA.\n",
    "        Dictionary (bool, opcional): Si es True, retorna un diccionario con metadatos de las secuencias.\n",
    "            Si es False, retorna el contenido bruto y un DataFrame con la información de las secuencias.\n",
    "            Por defecto es False.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - str: Contenido bruto del archivo FASTA.\n",
    "            - pandas.DataFrame o dict: DataFrame con metadatos de las secuencias si Dictionary es False,\n",
    "              de lo contrario un diccionario con los metadatos de las secuencias.\n",
    "\n",
    "    Ejemplo:\n",
    "        >>> contenido, info_secuencias = read_fasta(\"genoma.fna\")\n",
    "        >>> contenido, dicc_secuencias = read_fasta(\"genoma.fna\", Dictionary=True)\n",
    "    \"\"\"\n",
    "    with open(x, 'r') as f:\n",
    "        lectura = f.read()\n",
    "    dictionary = {}\n",
    "    starts, new_lines = find('>', lectura), find('\\n', lectura)\n",
    "    if len(starts) == 1:\n",
    "        en = 0\n",
    "        lectura = lectura[starts[en]:new_lines[en]+1] + lectura[new_lines[en]+1:].replace('\\n', '')\n",
    "        start_name, end_name, start_seq, end_seq = starts[en], new_lines[en*2], new_lines[en*2]+1, new_lines[-1]\n",
    "        dictionary[en] = {'start_name': start_name,\n",
    "                          'end_name': end_name,\n",
    "                          'len_name': end_name-start_name,\n",
    "                          'name': lectura[start_name:end_name],\n",
    "                          'start_seq': start_seq,\n",
    "                          'end_seq': end_seq,\n",
    "                          'len_seq': end_seq-start_seq,\n",
    "                          'seq': lectura[start_seq:end_seq]}\n",
    "    else:\n",
    "        # secuencias\n",
    "        # clave = (>.*\\n)\n",
    "        # valor = lectura[(key[-1].index+1)].*\\n #se considera que cada valor está entre \\n\n",
    "        for en in range(len(starts)):\n",
    "            start_name, end_name, start_seq, end_seq = starts[en], new_lines[en*2], new_lines[en*2]+1, new_lines[en*2+1]\n",
    "            dictionary[en] = {'start_name': start_name,\n",
    "                              'end_name': end_name,\n",
    "                              'len_name': end_name-start_name,\n",
    "                              'name': lectura[start_name:end_name],\n",
    "                              'start_seq': start_seq,\n",
    "                              'end_seq': end_seq,\n",
    "                              'len_seq': end_seq-start_seq,\n",
    "                              'seq': lectura[start_seq:end_seq]}\n",
    "    if not Dictionary:\n",
    "        return lectura, pd.DataFrame.from_dict(dictionary, orient='index').astype({\n",
    "            'start_name': 'uint32',\n",
    "            'end_name': 'uint32',\n",
    "            'len_name': 'uint32',\n",
    "            'name': object,\n",
    "            'start_seq': 'uint32',\n",
    "            'end_seq': 'uint32',\n",
    "            'len_seq': 'uint32',\n",
    "            'seq': object})\n",
    "    return lectura, dictionary\n",
    "\n",
    "def find(subcadena, texto):\n",
    "    \"\"\"\n",
    "    Busca todas las posiciones de una subcadena dentro de un texto.\n",
    "\n",
    "    Args:\n",
    "        subcadena (str): Subcadena a buscar en el texto.\n",
    "        texto (str): Texto donde se realiza la búsqueda.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de posiciones (índices) donde se encuentra la subcadena en el texto.\n",
    "\n",
    "    Ejemplo:\n",
    "        >>> find('a', 'banana')\n",
    "        [1, 3, 5]\n",
    "    \"\"\"\n",
    "    posiciones = []\n",
    "    indice = 0\n",
    "    while True:\n",
    "        indice = texto.find(subcadena, indice)\n",
    "        if indice == -1:\n",
    "            break\n",
    "        posiciones.append(indice)\n",
    "        indice += 1\n",
    "    return posiciones\n",
    "\n",
    "def result(csv_table, files_by_table, fasta_ext, species):\n",
    "    # data normalizada\n",
    "    data = pd.read_csv(csv_table, low_memory=False) # leyendo csv_table\n",
    "    data['normalize_species'] = data[['species']].map(normalize_species)\n",
    "\n",
    "    # especies normalizadas\n",
    "    norm_species = [normalize_species(ii) for ii in species]\n",
    "\n",
    "    # ficheros de interés por especies\n",
    "    fasta_files = [os.path.split(ii)[-1] for ii in glob(files_by_table+f'/*.{fasta_ext}')]\n",
    "    dict_genomas = {species[en]: np.unique([ii for ii in data[data['normalize_species'] == esp]['accession']]) for en,esp in enumerate(norm_species)}\n",
    "    dict_genomas = {clave: [file for file in fasta_files for ii in dict_genomas[clave] if file.startswith(ii)] for clave in dict_genomas}\n",
    "\n",
    "    samples = [list(ii) for ii in dict_genomas.values()]\n",
    "    labels = list(dict_genomas.keys())\n",
    "\n",
    "    # tsv output\n",
    "    OUTPUT='../Results/parse_metadata'\n",
    "    os.makedirs(OUTPUT, exist_ok=True)\n",
    "    out_labels = pd.DataFrame(labels, columns=['species'])\n",
    "    out_labels.to_csv(f'{OUTPUT}/labels.tsv', index=False, header=False)\n",
    "    out_samples = pd.DataFrame([samples])\n",
    "    out_samples.to_csv(f'{OUTPUT}/samples.tsv', index=False, header=False)\n",
    "\n",
    "    return out_labels, out_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876bccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especies\n",
    "species = [\"Bifidobacterium longum\", \"Escherichia fergusonii\", \"Bacillus_A cereus\", \"Xylella fastidiosa\"]\n",
    "\n",
    "# rutas\n",
    "csv_table = \"/data/Proyecto/Supplememtary_Table_1.csv\"\n",
    "files_by_table = \"/data/Proyecto/Data_forTAP\"\n",
    "fasta_ext = 'fna'\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# data normalizada\n",
    "data = pd.read_csv(csv_table, low_memory=False) # leyendo csv_table\n",
    "data['normalize_species'] = data[['species']].map(normalize_species)\n",
    "\n",
    "# especies normalizadas\n",
    "norm_species = [normalize_species(ii) for ii in species]\n",
    "\n",
    "# ficheros de interés por especies\n",
    "fasta_files = [os.path.split(ii)[-1] for ii in glob(files_by_table+f'/*.{fasta_ext}')] # todos los ficheros fasta\n",
    "labels = {}\n",
    "for en, esp_norm in enumerate(norm_species):\n",
    "    selection = data[data['normalize_species'] == esp_norm][['accession', 'checkm_marker_lineage',\n",
    "                                                             'ssu_silva_blast_subject_id',\n",
    "                                                             'ssu_silva_taxonomy', 'species']]\n",
    "    selection['filename'] = selection['accession'].apply(\n",
    "        lambda acc: next((f for f in fasta_files if f.startswith(acc)), None)\n",
    "    )\n",
    "    # Reordenar para que 'filename' sea la primera columna\n",
    "    cols = ['filename'] + [col for col in selection.columns if col != 'filename']\n",
    "    labels[species[en]] = selection[cols]\n",
    "\n",
    "# dict_genomas_short = {species[en]: \\\n",
    "#                 np.unique([ii for ii in data[data['normalize_species'] == esp]['accession']]) \\\n",
    "#                 for en,esp in enumerate(norm_species)} # el empezar del nombre\n",
    "# dict_genomas = {clave: [file for file in fasta_files for ii in dict_genomas_short[clave] \\\n",
    "#                 if file.startswith(ii)] for clave in dict_genomas_short} # el nombre completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2f0fcb35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[158]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pd.DataFrame.from_dict(labels, orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/osvaldo-tap/lib/python3.13/site-packages/pandas/core/frame.py:1922\u001b[39m, in \u001b[36mDataFrame.from_dict\u001b[39m\u001b[34m(cls, data, orient, dtype, columns)\u001b[39m\n\u001b[32m   1916\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1917\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for orient parameter. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1918\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1919\u001b[39m     )\n\u001b[32m   1921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data, index=index, columns=columns, dtype=dtype)\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     realdata = data[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/osvaldo-tap/lib/python3.13/site-packages/pandas/core/frame.py:867\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    859\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m             arrays,\n\u001b[32m    861\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m             typ=manager,\n\u001b[32m    865\u001b[39m         )\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m         mgr = ndarray_to_mgr(\n\u001b[32m    868\u001b[39m             data,\n\u001b[32m    869\u001b[39m             index,\n\u001b[32m    870\u001b[39m             columns,\n\u001b[32m    871\u001b[39m             dtype=dtype,\n\u001b[32m    872\u001b[39m             copy=copy,\n\u001b[32m    873\u001b[39m             typ=manager,\n\u001b[32m    874\u001b[39m         )\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    877\u001b[39m         {},\n\u001b[32m    878\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         typ=manager,\n\u001b[32m    882\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/osvaldo-tap/lib/python3.13/site-packages/pandas/core/internals/construction.py:319\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    314\u001b[39m     values = _ensure_2d(values)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     values = _prep_ndarraylike(values, copy=copy_on_sanitize)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values.dtype != dtype:\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[32m    323\u001b[39m     values = sanitize_array(\n\u001b[32m    324\u001b[39m         values,\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    328\u001b[39m         allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/osvaldo-tap/lib/python3.13/site-packages/pandas/core/internals/construction.py:575\u001b[39m, in \u001b[36m_prep_ndarraylike\u001b[39m\u001b[34m(values, copy)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# and platform dtype preservation\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m#  np.asarray would\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(values[\u001b[32m0\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     values = np.array([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[32m0\u001b[39m], np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[32m0\u001b[39m].ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    577\u001b[39m     \u001b[38;5;66;03m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[32m    578\u001b[39m     values = np.array([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(labels, orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osvaldo-tap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
